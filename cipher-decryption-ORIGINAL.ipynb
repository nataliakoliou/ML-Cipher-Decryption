{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0cec2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07692307692307693\n",
      "['ky', 'rg', 'ls', 'pb', 'fu', 'ie', 'bz', 'tr', 'of', 'vn', 'ya', 'zc', 'qq', 'jo', 'ni', 'sd', 'mm', 'hb', 'cp', 'wh', 'ew', 'xq', 'ut', 'dv', 'ak', 'gl']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import collections as col\n",
    "from pprint import pprint as ppr\n",
    "from collections import defaultdict as dd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def extract_feature_FR(letters_text, NL_text, accuracy):\n",
    "    feature_FR = dict(sorted({key: value/NL_text for key, value in dict(col.Counter(letters_text)).items()}.items()))\n",
    "    round_dict(feature_FR, accuracy)\n",
    "    return feature_FR\n",
    "\n",
    "def extract_feature_WL(alphabet, words, word_length, letters_times, accuracy):\n",
    "    feature_WL = dict.fromkeys(alphabet, 0)\n",
    "    if word_length == 1:\n",
    "        for w in words:\n",
    "            if len(w) == word_length and feature_WL[w] == 0:\n",
    "                feature_WL[w] = 1\n",
    "    elif has_domain(word_length, 2, 4):\n",
    "        for w in words:\n",
    "            if len(w) == word_length:\n",
    "                for l in list(w):\n",
    "                    feature_WL[l] += 1/letters_times.get(l)\n",
    "    elif has_domain(word_length, 5, 7):\n",
    "        for w in words:\n",
    "            if has_domain(len(w), 5, 7):\n",
    "                for l in list(w):\n",
    "                    feature_WL[l] += 1/letters_times.get(l)\n",
    "    elif has_domain(word_length, 8, 10):\n",
    "        for w in words:\n",
    "            if has_domain(len(w), 8, 10):\n",
    "                for l in list(w):\n",
    "                    feature_WL[l] += 1/letters_times.get(l)\n",
    "    else:\n",
    "        for w in words:\n",
    "            if len(w) >= word_length:\n",
    "                for l in list(w):\n",
    "                    feature_WL[l] += 1/letters_times.get(l)\n",
    "                    \n",
    "    round_dict(feature_WL, accuracy)\n",
    "    return feature_WL\n",
    "\n",
    "def extract_feature_SW(alphabet, case, words, letters_times, accuracy):\n",
    "    feature_SW = dict.fromkeys(alphabet, 0)\n",
    "    if \"first\" in case:\n",
    "        for w in words:\n",
    "            first = list(w)[0]\n",
    "            feature_SW[first] += 1/letters_times.get(first)\n",
    "    elif \"last\" in case:\n",
    "        for w in words:\n",
    "            last = list(w)[len(w)-1]\n",
    "            feature_SW[last] += 1/letters_times.get(last)    \n",
    "    else:\n",
    "        for w in words:\n",
    "            first = list(w)[0]\n",
    "            last = list(w)[len(w)-1]\n",
    "            if first == last:\n",
    "                feature_SW[first] += 1/letters_times.get(first)\n",
    "    round_dict(feature_SW, accuracy)\n",
    "    return feature_SW\n",
    "\n",
    "def extract_feature_DL(alphabet, words, letters_times, accuracy):\n",
    "    feature_DL = dict.fromkeys(alphabet, 0)\n",
    "    for w in words:\n",
    "        if len(w) != 1:\n",
    "            prev_letter = \"#\"\n",
    "            for l in list(w):\n",
    "                if prev_letter == l:\n",
    "                    feature_DL[l] += 1/letters_times.get(l)\n",
    "                prev_letter = l\n",
    "    return feature_DL\n",
    "\n",
    "def has_domain(var, point1, point2):\n",
    "    if var >= point1 and var <= point2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def minimize_dataset(old_dataset):  # removes duplicate words from text\n",
    "    new_dataset = []\n",
    "    for w in old_dataset: \n",
    "        if w not in new_dataset: \n",
    "            new_dataset.append(w)\n",
    "    return new_dataset\n",
    "\n",
    "def round_dict(dict, accuracy):\n",
    "    for key in dict: dict[key] = round(dict.get(key),accuracy)\n",
    "    return dict\n",
    "\n",
    "def get_letters(words):\n",
    "    temp = []\n",
    "    for w in words:\n",
    "        temp.append(list(w))\n",
    "    letters = [letter for word in temp for letter in word]\n",
    "    return letters\n",
    "\n",
    "def process(data_file, alphabet):\n",
    "    \n",
    "    accuracy = 10\n",
    "\n",
    "    with open(data_file, 'r') as f:\n",
    "        words_text = f.read().split()\n",
    "\n",
    "    letters_text = get_letters(words_text)\n",
    "    NL_text = len(letters_text)\n",
    "\n",
    "    words = minimize_dataset(words_text)\n",
    "    letters = get_letters(words)\n",
    "    NL = len(letters)\n",
    "    letters_times = dict(sorted({key: value for key, value in dict(col.Counter(letters)).items()}.items()))\n",
    "    letters_freqs = {key: value/NL for key, value in letters_times.items()}\n",
    "\n",
    "    feature_0 = extract_feature_FR(letters_text, NL_text, accuracy)\n",
    "    feature_1 = extract_feature_WL(alphabet, words, 1, letters_times, accuracy)\n",
    "    feature_2 = extract_feature_WL(alphabet, words, 2, letters_times, accuracy)\n",
    "    feature_3 = extract_feature_WL(alphabet, words, 3, letters_times, accuracy)\n",
    "    feature_4 = extract_feature_WL(alphabet, words, 4, letters_times, accuracy)\n",
    "    feature_5 = extract_feature_WL(alphabet, words, rand.randint(5,7), letters_times, accuracy)\n",
    "    feature_6 = extract_feature_WL(alphabet, words, rand.randint(8,10), letters_times, accuracy)\n",
    "    feature_7 = extract_feature_WL(alphabet, words, 11, letters_times, accuracy)\n",
    "    feature_8 = extract_feature_SW(alphabet, \"first\", words, letters_times, accuracy)\n",
    "    feature_9 = extract_feature_SW(alphabet, \"last\", words, letters_times, accuracy)\n",
    "    feature_10 = extract_feature_SW(alphabet, \"both\", words, letters_times, accuracy)\n",
    "    feature_11 = extract_feature_DL(alphabet, words, letters_times, accuracy)\n",
    "    \n",
    "    features = dd(list) # defining a dictionary\n",
    "\n",
    "# feature_0, feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7, feature_8, feature_9, feature_10, feature_11\n",
    "   \n",
    "    for d in (feature_0, feature_1, feature_2, feature_11):\n",
    "        for key, value in d.items():\n",
    "            features[key].append(value)\n",
    "    features = dict(features)      # get only the dictionary-part\n",
    "    features = [val for key, val in features.items()]     # convert dictionary of lists into a list of lists\n",
    "\n",
    "    X = np.array(features)\n",
    "\n",
    "    return X\n",
    "        \n",
    "def main():\n",
    "    \n",
    "    text_v1 = \"TESTING-tolstoy-anna-karenina-v1.txt\"\n",
    "    alphabet_v1 = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    \n",
    "    text_v2 = \"TESTING-tolstoy-war-and-peace.txt\"\n",
    "    alphabet_v2 = \"krlpfibtovyzqjnsmhcwexudag\"\n",
    "    \n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "    np.set_printoptions(suppress=True)  # to avoid scientific notation when printing\n",
    "\n",
    "    X_train = process(\"TRAINING-tolstoy-anna-karenina.txt\", alphabet)\n",
    "    y_train = np.array(alphabet)\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    X_test = process(text_v2, alphabet)\n",
    "    y_test = list(alphabet_v2)  # the actual y values of the test-text\n",
    "    y_pred = svc.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(y_test)\n",
    "    #print(y_pred)\n",
    "    print(accuracy)\n",
    "    \n",
    "    comparison = []\n",
    "    for l in range(len(alphabet)):\n",
    "        comparison.append(y_test[l]+y_pred[l])\n",
    "    print(comparison)\n",
    "  \n",
    "\"\"\"\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(confusion)\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7ba14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f10f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
