{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b0cec2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r', 'c', 'b', 'h', 'd', 't', 'k', 'o', 'u', 'm', 'g', 'e', 'v', 'l', 'n', 'w', 's', 'f', 'y', 'p', 'x', 'z', 'q', 'j', 'i', 'a']\n",
      "0.15384615384615385\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import collections as col\n",
    "from pprint import pprint as ppr\n",
    "from collections import defaultdict as dd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def extract_feature_FR(alphabet, letters_text, NL_text, accuracy):\n",
    "    feature_FR = {}\n",
    "    temp = dict(sorted({key: value/NL_text for key, value in dict(col.Counter(letters_text)).items()}.items()))\n",
    "    for key in temp:\n",
    "        if key in alphabet:\n",
    "            feature_FR[key] = temp.get(key)\n",
    "    round_dict(feature_FR, accuracy)\n",
    "    return feature_FR\n",
    "\n",
    "def extract_feature_WL(alphabet, words, word_length, letters_times, accuracy):\n",
    "    feature_WL = dict.fromkeys(alphabet, 0)\n",
    "    if word_length == 1:\n",
    "        for w in words:\n",
    "            if w not in alphabet:\n",
    "                continue\n",
    "            elif len(w) == word_length and feature_WL[w] == 0:\n",
    "                feature_WL[w] = 1\n",
    "    elif has_domain(word_length, 2, 4):\n",
    "        for w in words:\n",
    "            if len(w) == word_length:\n",
    "                for l in list(w):\n",
    "                    if l not in alphabet:\n",
    "                        continue\n",
    "                    else:\n",
    "                        feature_WL[l] += 1/letters_times.get(l)\n",
    "    elif has_domain(word_length, 5, 7):\n",
    "        for w in words:\n",
    "            if has_domain(len(w), 5, 7):\n",
    "                for l in list(w):\n",
    "                    if l not in alphabet:\n",
    "                        continue\n",
    "                    else:\n",
    "                        feature_WL[l] += 1/letters_times.get(l)\n",
    "    elif has_domain(word_length, 8, 10):\n",
    "        for w in words:\n",
    "            if has_domain(len(w), 8, 10):\n",
    "                for l in list(w):\n",
    "                    if l not in alphabet:\n",
    "                        continue\n",
    "                    else:                    \n",
    "                        feature_WL[l] += 1/letters_times.get(l)\n",
    "    else:\n",
    "        for w in words:\n",
    "            if len(w) >= word_length:\n",
    "                for l in list(w):\n",
    "                    if l not in alphabet:\n",
    "                        continue\n",
    "                    else:                    \n",
    "                        feature_WL[l] += 1/letters_times.get(l)\n",
    "                    \n",
    "    round_dict(feature_WL, accuracy)\n",
    "    return feature_WL\n",
    "\n",
    "def extract_feature_SW(alphabet, case, words, letters_times, accuracy):\n",
    "    feature_SW = dict.fromkeys(alphabet, 0)\n",
    "    if \"first\" in case:\n",
    "        for w in words:\n",
    "            first = list(w)[0]\n",
    "            if first not in alphabet:\n",
    "                continue\n",
    "            else:\n",
    "                feature_SW[first] += 1/letters_times.get(first)\n",
    "    elif \"last\" in case:\n",
    "        for w in words:\n",
    "            last = list(w)[len(w)-1]\n",
    "            if last not in alphabet:\n",
    "                continue\n",
    "            else:            \n",
    "                feature_SW[last] += 1/letters_times.get(last)    \n",
    "    else:\n",
    "        for w in words:\n",
    "            first = list(w)[0]\n",
    "            last = list(w)[len(w)-1]\n",
    "            if first == last and first in alphabet:\n",
    "                feature_SW[first] += 1/letters_times.get(first)\n",
    "    round_dict(feature_SW, accuracy)\n",
    "    return feature_SW\n",
    "\n",
    "def extract_feature_DL(alphabet, words, letters_times, accuracy):\n",
    "    feature_DL = dict.fromkeys(alphabet, 0)\n",
    "    for w in words:\n",
    "        if len(w) != 1:\n",
    "            prev_letter = \"#\"\n",
    "            for l in list(w):\n",
    "                if prev_letter == l and l in alphabet:\n",
    "                    feature_DL[l] += 1/letters_times.get(l)\n",
    "                prev_letter = l\n",
    "    return feature_DL\n",
    "\n",
    "def has_domain(var, point1, point2):\n",
    "    if var >= point1 and var <= point2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def minimize_dataset(old_dataset):  # removes duplicate words from text\n",
    "    new_dataset = []\n",
    "    for w in old_dataset: \n",
    "        if w not in new_dataset: \n",
    "            new_dataset.append(w)\n",
    "    return new_dataset\n",
    "\n",
    "def round_dict(dict, accuracy):\n",
    "    for key in dict: dict[key] = round(dict.get(key),accuracy)\n",
    "    return dict\n",
    "\n",
    "def get_letters(words):\n",
    "    temp = []\n",
    "    for w in words:\n",
    "        temp.append(list(w))\n",
    "    letters = [letter for word in temp for letter in word]\n",
    "    return letters\n",
    "\n",
    "def is_shaffled_alphabet(key):\n",
    "    if len(key) == len(set(key)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def update_y(fy, y):\n",
    "    count = 0\n",
    "    for i in range(len(fy)):\n",
    "        if fy[i] == \"NN\" and y[count] not in fy:\n",
    "            fy[i] = y[count]\n",
    "            count += 1        \n",
    "    return fy\n",
    "\n",
    "def update_alphabet(alphabet, fy):\n",
    "    new_AB = []\n",
    "    for val in alphabet:\n",
    "        if val not in fy:\n",
    "            new_AB.append(val)\n",
    "    return new_AB\n",
    "\n",
    "def process(data_file, alphabet):\n",
    "    \n",
    "    accuracy = 10\n",
    "\n",
    "    with open(data_file, 'r') as f:\n",
    "        words_text = f.read().split()\n",
    "\n",
    "    letters_text = get_letters(words_text)\n",
    "    NL_text = len(letters_text)\n",
    "\n",
    "    words = minimize_dataset(words_text)\n",
    "    letters = get_letters(words)\n",
    "    NL = len(letters)\n",
    "    letters_times = dict(sorted({key: value for key, value in dict(col.Counter(letters)).items()}.items()))\n",
    "    letters_freqs = {key: value/NL for key, value in letters_times.items()}\n",
    "\n",
    "    feature_0 = extract_feature_FR(alphabet, letters_text, NL_text, accuracy)\n",
    "    feature_1 = extract_feature_WL(alphabet, words, 1, letters_times, accuracy)\n",
    "    feature_2 = extract_feature_WL(alphabet, words, 2, letters_times, accuracy)\n",
    "    feature_3 = extract_feature_WL(alphabet, words, 3, letters_times, accuracy)\n",
    "    feature_4 = extract_feature_WL(alphabet, words, 4, letters_times, accuracy)\n",
    "    feature_5 = extract_feature_WL(alphabet, words, rand.randint(5,7), letters_times, accuracy)\n",
    "    feature_6 = extract_feature_WL(alphabet, words, rand.randint(8,10), letters_times, accuracy)\n",
    "    feature_7 = extract_feature_WL(alphabet, words, 11, letters_times, accuracy)\n",
    "    feature_8 = extract_feature_SW(alphabet, \"first\", words, letters_times, accuracy)\n",
    "    feature_9 = extract_feature_SW(alphabet, \"last\", words, letters_times, accuracy)\n",
    "    feature_10 = extract_feature_SW(alphabet, \"both\", words, letters_times, accuracy)\n",
    "    feature_11 = extract_feature_DL(alphabet, words, letters_times, accuracy)\n",
    "    \n",
    "    features = dd(list) # defining a dictionary\n",
    "\n",
    "# feature_0, feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7, feature_8, feature_9, feature_10, feature_11\n",
    "   \n",
    "    for d in (feature_0, feature_1, feature_2, feature_11):\n",
    "        for key, value in d.items():\n",
    "            features[key].append(value)\n",
    "    features = dict(features)      # get only the dictionary-part\n",
    "    features = [val for key, val in features.items()]     # convert dictionary of lists into a list of lists\n",
    "\n",
    "    X = np.array(features)\n",
    "\n",
    "    return X\n",
    "        \n",
    "def main():\n",
    "    \n",
    "    done = False\n",
    "    text_v1 = \"TESTING-tolstoy-anna-karenina-v1.txt\"\n",
    "    alphabet_v1 = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    \n",
    "    text_v2 = \"TESTING-tolstoy-anna-karenina-v2.txt\"\n",
    "    alphabet_v2 = \"rcheyobdtmgiskuqlapfzjxnvw\"\n",
    "    \n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "    final_y = [\"NN\" for a in range(len(alphabet))]\n",
    "    np.set_printoptions(suppress=True)  # to avoid scientific notation when printing\n",
    "\n",
    "    while not done:\n",
    "        X_train = process(\"TRAINING-tolstoy-anna-karenina.txt\", alphabet)\n",
    "        y_train = np.array(alphabet)\n",
    "        svc = SVC()\n",
    "        svc.fit(X_train, y_train)\n",
    "\n",
    "        X_test = process(text_v2, alphabet)\n",
    "        y_test = list(alphabet_v2)  # the actual y values of the test-text\n",
    "        y_pred = svc.predict(X_test)\n",
    "        final_y = update_y(final_y, y_pred)\n",
    "\n",
    "        #print(y_test)\n",
    "        #print(y_pred)\n",
    "\n",
    "        #comparison = []\n",
    "        #for l in range(len(alphabet)):\n",
    "            #comparison.append(y_test[l]+final_y[l])\n",
    "        #print(comparison)\n",
    "\n",
    "        if is_shaffled_alphabet(y_pred):\n",
    "            done = True\n",
    "        else:\n",
    "            alphabet = update_alphabet(alphabet, final_y)\n",
    "            if len(alphabet) == 1:\n",
    "                final_y = update_y(final_y, alphabet)  # no prediction needed!\n",
    "                done = True\n",
    "  \n",
    "    print(final_y)\n",
    "    accuracy = accuracy_score(y_test, final_y)\n",
    "    print(accuracy)\n",
    "\"\"\"\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(confusion)\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7ba14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f10f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
